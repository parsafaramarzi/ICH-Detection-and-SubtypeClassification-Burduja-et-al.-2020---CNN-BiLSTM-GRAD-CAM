# ICH-Detection-and-SubtypeClassification-Burduja-et-al.-2020---CNN-BiLSTM-GRAD-CAM

**Note:** This is a community implementation/fork of the architecture described in the paper. The **official repository** is maintained by the authors at: [https://github.com/warchildmd/ihd](https://github.com/warchildmd/ihd).

This repository implements the architecture proposed in the paper **"Accurate and Efficient Intracranial Hemorrhage Detection and Subtype Classification in 3D CT Scans with Convolutional and Long Short-Term Memory Neural Networks"** by Burduja et al. (2020).

The primary goal of this system is **patient-level classification**, meaning it outputs a single diagnosis for the entire 3D CT scan: (1) ICH presence, and (2) Classification of the five ICH subtypes (Intraparenchymal, Subarachnoid, Epidural, Subdural, Intraventricular).

## ‚ö†Ô∏è Data Licensing and Compliance (IMPORTANT)

This repository contains only the **code** for the model architecture and training pipeline.

The raw CT scan data is restricted health data governed by the **PhysioNet Restricted Health Data License**. Sharing the raw data violates the license agreement and patient privacy standards.

To run this project, you must:

1.  Register and agree to the license terms on the official PhysioNet website.
2.  Download the full dataset locally using the following link and place the files in the `/data` directory.

**Dataset Download Link:**
[https://physionet.org/content/ct-ich/1.3.1/](https://physionet.org/content/ct-ich/1.3.1/)

## üß† Technical Implementation Details: The Hybrid CNN-BiLSTM Architecture

The model is a novel two-stage, two-loss hybrid network designed to efficiently process a variable-length sequence of 2D CT slices to produce a 3D volume (patient-level) diagnosis.



### 1. Stage 1: Spatial Feature Extraction (The CNN Backbone)

This stage is responsible for identifying relevant patterns *within* a single slice.

* **Component:** A standard CNN (e.g., ResNet-18 or ResNet-50, adapted for single-channel grayscale input).
* **Input:** A single, pre-processed 2D CT slice (`256x256x1`).
* **Output:** A fixed-size **slice feature embedding** (e.g., 512-1024 dimensions) which encapsulates the spatial information learned from the slice.
* **Auxiliary Task:** The CNN's output features are also used to predict the slice-level labels. This creates an **Auxiliary Loss** that regularizes the network, ensuring the features passed to the next stage are strongly predictive of hemorrhage presence at the slice level.

### 2. Stage 2: Sequential Context Modeling (The Bi-LSTM)

This stage is responsible for aggregating the slice-level features across the Z-axis (depth) to understand the full 3D context of the patient's hemorrhage.

* **Component:** A Bidirectional Long Short-Term Memory (Bi-LSTM) network.
* **Input:** A **sequence of feature embeddings** generated by the CNN for a fixed set of sampled slices from one patient's scan.
* **Mechanism:** The Bi-LSTM processes the sequence in both the forward and backward directions. This capability is crucial for capturing how a lesion begins, progresses, and ends across the volumetric data, mimicking a radiologist scrolling through the scan.
* **Patient-Level Output:** The final hidden state of the Bi-LSTM is passed through a classifier (Fully Connected layer + Sigmoid) to produce the **final patient-level diagnosis**.

### Loss Function

The training objective is defined by a combined loss function, balancing the slice-level task and the final patient-level task:

$$\text{Loss}_{\text{Total}} = (1 - \lambda) \cdot \text{Loss}_{\text{Scan}} + \lambda \cdot \text{Loss}_{\text{Slice}}$$

Both losses are based on **Binary Cross-Entropy (BCE) loss** to handle the multi-label nature of the classification. The weighting factor $\lambda$ (Lambda) is set via the `AUXILIARY_LOSS_WEIGHT` parameter (default 0.5).

## 3. Data Pipeline Implementation: Fixed-Length Sampling

The variable slice count across patient scans (ranging from 30 to 60+ slices) necessitates a sophisticated data preparation pipeline to ensure the Bi-LSTM receives consistent input.

### Pre-processing Steps

1.  **NIfTI Loading and HU Conversion:** 3D volumes are loaded (`.nii`) and raw pixel values are converted to Hounsfield Units (HU).
2.  **Windowing and Normalization:** HU values are clinically windowed (e.g., Brain Window) to enhance contrast for specific tissues and then normalized (0-1 range).
3.  **Resizing:** Each slice is uniformly resized to `IMG_SIZE` (e.g., 256x256).

### Fixed-Length Slice Sampling (Sequence Generation)

* **Implementation:** The `HemorrhageDataset` calculates a step size based on the total number of slices ($N$) and the required sequence length ($S$, e.g., 16).
* **Sampling:** It selects exactly $S$ slices at uniform intervals throughout the volume's depth. This technique ensures that the resulting input tensor for the Bi-LSTM is always a fixed size, preventing errors during batched training and providing the model with a statistically representative sample of the full 3D scan.
* **Final Batch Shape:** The input tensor for a batch of $B$ patients has the dimensions: `[Batch Size (B) x Sequence Length (S) x 1 (Channel) x Height x Width]`.

## üõ†Ô∏è Setup and Installation

### Prerequisites

* Python 3.8+
* PyTorch (CPU or CUDA)

### Dependencies

Install the necessary Python libraries:

```bash
pip install torch torchvision torchaudio numpy pandas scikit-learn nibabel opencv-python albumentations
```

### Data Structure

Once the data is downloaded, the project expects the input data to be organized as follows:

```
/data
‚îú‚îÄ‚îÄ hemorrhage_diagnosis_raw_ct.csv   # Master CSV with slice-level labels
‚îî‚îÄ‚îÄ ct_scans/
    ‚îú‚îÄ‚îÄ 001.nii                      # NIfTI file for Patient 1 (3D Volume)
    ‚îú‚îÄ‚îÄ 002.nii
    ‚îî‚îÄ‚îÄ ...
```

## üöÄ Training

The `src/train.py` script executes the entire training pipeline.

### Execution

To begin training:

```bash
python src/train.py
```

### Key Training Parameters (in `src/train.py`)

| Parameter | Default Value | Description |
| :--- | :--- | :--- |
| `BATCH_SIZE` | `4` | Number of patients per batch. |
| `IMG_SIZE` | `256` | Target pixel size for slices. |
| `EPOCHS` | `10` | Total training epochs. |
| `AUXILIARY_LOSS_WEIGHT` | `0.5` | Weight ($\lambda$) for the auxiliary slice-level loss. |
"""
